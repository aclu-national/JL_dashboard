Conducting text analysis we get the following: 

| Word    |   Count |
|:--------|--------:|
| offic   |     543 |
| right   |     315 |
| polic   |     311 |
| arrest  |     278 |
| time    |     257 |
| told    |     245 |
| ask     |     238 |
| call    |     236 |
| stop    |     234 |
| get     |     233 |
| state   |     230 |
| violat  |     220 |
| said    |     216 |
| go      |     213 |
| would   |     208 |
| court   |     196 |
| back    |     191 |
| charg   |     189 |
| car     |     177 |
| need    |     171 |
| legal   |     170 |
| search  |     166 |
| one     |     165 |
| vehicl  |     164 |
| also    |     162 |
| day     |     161 |
| due     |     161 |
| law     |     159 |
| use     |     150 |
| without |     149 |

| Bigram                 |   Count |
|:-----------------------|--------:|
| ('due', 'process')     |      80 |
| ('polic', 'offic')     |      58 |
| ('civil', 'right')     |      44 |
| ('law', 'enforc')      |      43 |
| ('new', 'orlean')      |      38 |
| ('traffic', 'stop')    |      33 |
| ('mental', 'health')   |      31 |
| ('court', 'date')      |      31 |
| ('commit', 'crime')    |      31 |
| ('amend', 'right')     |      30 |
| ('phone', 'call')      |      30 |
| ('polic', 'depart')    |      28 |
| ('right', 'violat')    |      27 |
| ('sheriff', 'offic')   |      26 |
| ('jennif', 'martin')   |      26 |
| ('violat', 'right')    |      25 |
| ('legal', 'represent') |      25 |
| ('process', 'violat')  |      24 |
| ('crime', 'lab')       |      24 |
| ('bodi', 'camera')     |      23 |
| ('parish', 'sheriff')  |      22 |
| ('polic', 'report')    |      22 |
| ('even', 'though')     |      21 |
| ('camera', 'footag')   |      21 |
| ('need', 'help')       |      21 |
| ('violat', 'due')      |      21 |
| ('tri', 'get')         |      20 |
| ('clear', 'violat')    |      20 |
| ('fals', 'arrest')     |      19 |
| ('stop', 'sign')       |      19 |

| Trigram                           |   Count |
|:----------------------------------|--------:|
| ('due', 'process', 'violat')      |      24 |
| ('violat', 'due', 'process')      |      20 |
| ('clear', 'violat', 'due')        |      18 |
| ('due', 'process', 'polic')       |      18 |
| ('parish', 'sheriff', 'offic')    |      16 |
| ('bodi', 'camera', 'footag')      |      15 |
| ('cruel', 'unusu', 'punish')      |      12 |
| ('rais', 'seriou', 'concern')     |      12 |
| ('proper', 'legal', 'counsel')    |      12 |
| ('law', 'enforc', 'offic')        |      11 |
| ('within', 'hour', 'requir')      |      10 |
| ('hour', 'requir', 'law')         |      10 |
| ('civil', 'right', 'violat')      |      10 |
| ('charg', 'possess', 'intent')    |      10 |
| ('trash', 'heap', 'call')         |       9 |
| ('heap', 'call', 'car')           |       9 |
| ('call', 'car', 'upon')           |       9 |
| ('car', 'upon', 'inspect')        |       9 |
| ('upon', 'inspect', 'vehicl')     |       9 |
| ('inspect', 'vehicl', 'found')    |       9 |
| ('vehicl', 'found', 'complet')    |       9 |
| ('found', 'complet', 'ransack')   |       9 |
| ('complet', 'ransack', 'radio')   |       9 |
| ('ransack', 'radio', 'rip')       |       9 |
| ('radio', 'rip', 'dashboard')     |       9 |
| ('rip', 'dashboard', 'interior')  |       9 |
| ('dashboard', 'interior', 'door') |       9 |
| ('interior', 'door', 'panel')     |       9 |
| ('door', 'panel', 'torn')         |       9 |
| ('panel', 'torn', 'floorboard')   |       9 |

| Place             |   Count |
|:------------------|--------:|
| Louisiana         |      57 |
| New Orleans       |      30 |
| LA                |      12 |
| Mississippi       |      11 |
| US                |      11 |
| U.S.              |      10 |
| St Tammany        |       8 |
| Baton Rouge       |       7 |
| the United States |       7 |
| Florida           |       6 |
| Brandon           |       6 |
| Shreveport        |       5 |
| Concordia         |       4 |
| La.               |       4 |
| Massachusetts     |       4 |
| California        |       4 |
| West              |       4 |
| BB                |       4 |
| R.S.              |       4 |
| Russia            |       4 |
| IV                |       4 |
| Touchet           |       4 |
| Angola            |       3 |
| Lucas             |       3 |
| Cordell           |       3 |
| Warden            |       3 |
| U.S.C.            |       3 |
| Utah              |       3 |
| Texas             |       3 |
| USA               |       3 |

| Noun     |   Count |
|:---------|--------:|
| police   |     245 |
| officer  |     192 |
| time     |     172 |
| officers |     168 |
| rights   |     166 |
| car      |     161 |
| court    |     153 |
| vehicle  |     142 |
| jail     |     115 |
| law      |     114 |
| stop     |     114 |
| evidence |     111 |
| arrest   |     104 |
| phone    |      96 |
| case     |      92 |
| people   |      88 |
| school   |      87 |
| days     |      85 |
| charges  |      84 |
| crime    |      81 |
| process  |      81 |
| son      |      80 |
| way      |      79 |
| years    |      79 |
| incident |      78 |
| family   |      73 |
| day      |      72 |
| state    |      71 |
| times    |      68 |
| life     |      67 |

| Verb      |   Count |
|:----------|--------:|
| told      |     239 |
| said      |     213 |
| asked     |     160 |
| believe   |     112 |
| going     |     108 |
| arrested  |     104 |
| know      |     101 |
| went      |      91 |
| got       |      91 |
| called    |      87 |
| need      |      77 |
| including |      75 |
| stated    |      75 |
| came      |      74 |
| left      |      68 |
| pulled    |      67 |
| denied    |      63 |
| trying    |      62 |
| found     |      61 |
| took      |      61 |
| want      |      58 |
| given     |      57 |
| informed  |      57 |
| help      |      56 |
| refused   |      55 |
| let       |      50 |
| speak     |      48 |
| find      |      48 |
| held      |      47 |
| having    |      46 |


R version 4.3.2 (2023-10-31) -- "Eye Holes"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: aarch64-apple-darwin20 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> reticulate::repl_python()
Python 3.11.4 (/Library/Frameworks/Python.framework/Versions/3.11/bin/python3.11)
Reticulate 1.30 REPL -- A Python interpreter in R.
Enter 'exit' or 'quit' to exit the REPL and return to R.
>>> # -------------------------- Loading Packages and Data -------------------------
>>> 
>>> # Importing Packages
>>> import json
>>> import string
>>> import spacy
>>> from nltk.util import ngrams
>>> from nltk.tokenize import word_tokenize, sent_tokenize
>>> from nltk.corpus import stopwords
>>> from nltk.stem import PorterStemmer
>>> import ssl
>>> from collections import Counter, defaultdict
>>> from sentence_transformers import SentenceTransformer, util
>>> import pandas as pd
>>> import re
>>> from dataclasses import dataclass
>>> 
>>> # try:
>>> #     _create_unverified_https_context = ssl._create_unverified_context
>>> # except AttributeError:
>>> #     pass
>>> # else:
>>> #     ssl._create_default_https_context = _create_unverified_https_context
>>> # 
>>> # nltk.download("stopwords")
>>> # nltk.download('punkt')
>>> 
>>> # Loading JSON of narratives
>>> with open('narrative_list.json') as f:
...     narrative_list = json.load(f)
...     
... # Getting distinct narratives
... narrative_list = list(set(narrative_list))
>>> 
>>> # Removing none and NaN
>>> cleaned_list = [x for x in narrative_list if x is not None and x == x]
>>> 
>>> # Defining stop words and stemmer
>>> stop_words = set(stopwords.words("english"))
>>> stemmer = PorterStemmer()
>>> 
>>> def counter_to_markdown(counter, title):
...     df = pd.DataFrame(counter.most_common(n), columns=[title, 'Count'])
...     return df.to_markdown(index=False)
...     
... # ------------------------------ Creating Lists --------------------------------
... 
>>> # Creating necessary lists
>>> words = [word for paragraph in cleaned_list for word in word_tokenize(paragraph) if word.casefold() not in stop_words and word.isalpha()]
>>> words_stemmed = [stemmer.stem(word) for word in words]
>>> bigrams = [bigram for paragraph in cleaned_list for bigram in ngrams([word.lower() for word in word_tokenize(paragraph) if word.isalpha()], 2)]
>>> trigrams = [trigram for paragraph in cleaned_list for trigram in ngrams([word.lower() for word in word_tokenize(paragraph) if word.isalpha()], 3)]
>>> bigrams_cleaned = [bigram for paragraph in cleaned_list for bigram in ngrams([stemmer.stem(word.lower()) for word in word_tokenize(paragraph) if word.isalpha() and word.casefold() not in stop_words], 2)]
>>> trigrams_cleaned = [bigram for paragraph in cleaned_list for bigram in ngrams([stemmer.stem(word.lower()) for word in word_tokenize(paragraph) if word.isalpha() and word.casefold() not in stop_words], 3)]
>>> sentences = [sentence for paragraph in cleaned_list for sentence in sent_tokenize(paragraph)]
>>>    
>>> # Loading Spacy library
>>> nlp = spacy.load("en_core_web_sm")
>>> 
>>> persons = [ent.text for sentence in sentences for ent in nlp(sentence).ents if ent.label_ == "PERSON"]
>>> places = [ent.text for sentence in sentences for ent in nlp(sentence).ents if ent.label_ in ("GPE", "LOC")]
>>> nouns = [token.text for sentence in sentences for token in nlp(sentence) if token.pos_ == "NOUN"  and not token.is_stop]
>>> verbs = [token.text for sentence in sentences for token in nlp(sentence) if token.pos_ == "VERB"  and not token.is_stop]
>>> adjectives = [token.text for sentence in sentences for token in nlp(sentence) if token.pos_ == "ADJ"  and not token.is_stop]
>>> 
>>> # --------------------------------- Counts ------------------------------------
>>> 
>>> # How many want to see
>>> n = 30
>>> 
>>> # Most common stemmed words
>>> print(counter_to_markdown(Counter(words_stemmed), "Word"))
| Word    |   Count |
|:--------|--------:|
| offic   |     543 |
| right   |     315 |
| polic   |     311 |
| arrest  |     278 |
| time    |     257 |
| told    |     245 |
| ask     |     238 |
| call    |     236 |
| stop    |     234 |
| get     |     233 |
| state   |     230 |
| violat  |     220 |
| said    |     216 |
| go      |     213 |
| would   |     208 |
| court   |     196 |
| back    |     191 |
| charg   |     189 |
| car     |     177 |
| need    |     171 |
| legal   |     170 |
| search  |     166 |
| one     |     165 |
| vehicl  |     164 |
| also    |     162 |
| day     |     161 |
| due     |     161 |
| law     |     159 |
| use     |     150 |
| without |     149 |
>>> 
>>> # Most common bigrams
>>> print(counter_to_markdown(Counter(bigrams_cleaned), "Bigram"))
| Bigram                 |   Count |
|:-----------------------|--------:|
| ('due', 'process')     |      80 |
| ('polic', 'offic')     |      58 |
| ('civil', 'right')     |      44 |
| ('law', 'enforc')      |      43 |
| ('new', 'orlean')      |      38 |
| ('traffic', 'stop')    |      33 |
| ('mental', 'health')   |      31 |
| ('court', 'date')      |      31 |
| ('commit', 'crime')    |      31 |
| ('amend', 'right')     |      30 |
| ('phone', 'call')      |      30 |
| ('polic', 'depart')    |      28 |
| ('right', 'violat')    |      27 |
| ('sheriff', 'offic')   |      26 |
| ('jennif', 'martin')   |      26 |
| ('violat', 'right')    |      25 |
| ('legal', 'represent') |      25 |
| ('process', 'violat')  |      24 |
| ('crime', 'lab')       |      24 |
| ('bodi', 'camera')     |      23 |
| ('parish', 'sheriff')  |      22 |
| ('polic', 'report')    |      22 |
| ('even', 'though')     |      21 |
| ('camera', 'footag')   |      21 |
| ('need', 'help')       |      21 |
| ('violat', 'due')      |      21 |
| ('tri', 'get')         |      20 |
| ('clear', 'violat')    |      20 |
| ('fals', 'arrest')     |      19 |
| ('stop', 'sign')       |      19 |
>>> 
>>> # Most common trigrams
>>> print(counter_to_markdown(Counter(trigrams_cleaned), "Trigram"))
| Trigram                           |   Count |
|:----------------------------------|--------:|
| ('due', 'process', 'violat')      |      24 |
| ('violat', 'due', 'process')      |      20 |
| ('clear', 'violat', 'due')        |      18 |
| ('due', 'process', 'polic')       |      18 |
| ('parish', 'sheriff', 'offic')    |      16 |
| ('bodi', 'camera', 'footag')      |      15 |
| ('cruel', 'unusu', 'punish')      |      12 |
| ('rais', 'seriou', 'concern')     |      12 |
| ('proper', 'legal', 'counsel')    |      12 |
| ('law', 'enforc', 'offic')        |      11 |
| ('within', 'hour', 'requir')      |      10 |
| ('hour', 'requir', 'law')         |      10 |
| ('civil', 'right', 'violat')      |      10 |
| ('charg', 'possess', 'intent')    |      10 |
| ('trash', 'heap', 'call')         |       9 |
| ('heap', 'call', 'car')           |       9 |
| ('call', 'car', 'upon')           |       9 |
| ('car', 'upon', 'inspect')        |       9 |
| ('upon', 'inspect', 'vehicl')     |       9 |
| ('inspect', 'vehicl', 'found')    |       9 |
| ('vehicl', 'found', 'complet')    |       9 |
| ('found', 'complet', 'ransack')   |       9 |
| ('complet', 'ransack', 'radio')   |       9 |
| ('ransack', 'radio', 'rip')       |       9 |
| ('radio', 'rip', 'dashboard')     |       9 |
| ('rip', 'dashboard', 'interior')  |       9 |
| ('dashboard', 'interior', 'door') |       9 |
| ('interior', 'door', 'panel')     |       9 |
| ('door', 'panel', 'torn')         |       9 |
| ('panel', 'torn', 'floorboard')   |       9 |
>>> 
>>> # Most common people
>>> print(counter_to_markdown(Counter(persons), "Person"))
| Person             |   Count |
|:-------------------|--------:|
| Brandon            |      79 |
| Fusilier           |      50 |
| Reuben             |      27 |
| Jennifer Martin    |      24 |
| Wilcox             |      23 |
| Kevin              |      18 |
| Levi               |      17 |
| Sam                |      14 |
| Darryl             |      12 |
| Mike               |      12 |
| Morris             |      10 |
| Brandon Fontenot   |       9 |
| Rucker             |       9 |
| Louisiana Statutes |       8 |
| Hawkins            |       7 |
| Anderson           |       7 |
| Intervene          |       7 |
| marijuana          |       6 |
| Martin             |       6 |
| Anglia Touchet     |       6 |
| Watson             |       6 |
| Pigtail            |       6 |
| mike               |       6 |
| Tramadol           |       6 |
| Maureen            |       6 |
| Ellis              |       6 |
| Livingston Parish  |       6 |
| Jefferson Parish   |       5 |
| Sgt                |       5 |
| Ricky Durrett      |       5 |
>>> 
>>> # Most common places
>>> print(counter_to_markdown(Counter(places), "Place"))
| Place             |   Count |
|:------------------|--------:|
| Louisiana         |      57 |
| New Orleans       |      30 |
| LA                |      12 |
| Mississippi       |      11 |
| US                |      11 |
| U.S.              |      10 |
| St Tammany        |       8 |
| Baton Rouge       |       7 |
| the United States |       7 |
| Florida           |       6 |
| Brandon           |       6 |
| Shreveport        |       5 |
| Concordia         |       4 |
| La.               |       4 |
| Massachusetts     |       4 |
| California        |       4 |
| West              |       4 |
| BB                |       4 |
| R.S.              |       4 |
| Russia            |       4 |
| IV                |       4 |
| Touchet           |       4 |
| Angola            |       3 |
| Lucas             |       3 |
| Cordell           |       3 |
| Warden            |       3 |
| U.S.C.            |       3 |
| Utah              |       3 |
| Texas             |       3 |
| USA               |       3 |
>>> 
>>> # Most common nouns
>>> print(counter_to_markdown(Counter(nouns), "Noun"))
| Noun     |   Count |
|:---------|--------:|
| police   |     245 |
| officer  |     192 |
| time     |     172 |
| officers |     168 |
| rights   |     166 |
| car      |     161 |
| court    |     153 |
| vehicle  |     142 |
| jail     |     115 |
| law      |     114 |
| stop     |     114 |
| evidence |     111 |
| arrest   |     104 |
| phone    |      96 |
| case     |      92 |
| people   |      88 |
| school   |      87 |
| days     |      85 |
| charges  |      84 |
| crime    |      81 |
| process  |      81 |
| son      |      80 |
| way      |      79 |
| years    |      79 |
| incident |      78 |
| family   |      73 |
| day      |      72 |
| state    |      71 |
| times    |      68 |
| life     |      67 |
>>> 
>>> # Most common verbs
>>> print(counter_to_markdown(Counter(verbs), "Verb"))
| Verb      |   Count |
|:----------|--------:|
| told      |     239 |
| said      |     213 |
| asked     |     160 |
| believe   |     112 |
| going     |     108 |
| arrested  |     104 |
| know      |     101 |
| went      |      91 |
| got       |      91 |
| called    |      87 |
| need      |      77 |
| including |      75 |
| stated    |      75 |
| came      |      74 |
| left      |      68 |
| pulled    |      67 |
| denied    |      63 |
| trying    |      62 |
| found     |      61 |
| took      |      61 |
| want      |      58 |
| given     |      57 |
| informed  |      57 |
| help      |      56 |
| refused   |      55 |
| let       |      50 |
| speak     |      48 |
| find      |      48 |
| held      |      47 |
| having    |      46 |
>>> 
>>> # Most common adjectives
>>> print(counter_to_markdown(Counter(adjectives), "Adjective"))
| Adjective   |   Count |
|:------------|--------:|
| legal       |     141 |
| medical     |      98 |
| public      |      74 |
| false       |      59 |
| clear       |      58 |
| multiple    |      54 |
| mental      |      51 |
| proper      |      49 |
| unlawful    |      45 |
| civil       |      44 |
| black       |      39 |
| able        |      38 |
| high        |      35 |
| old         |      33 |
| white       |      33 |
| criminal    |      33 |
| right       |      31 |
| entire      |      30 |
| complete    |      30 |
| personal    |      29 |
| new         |      28 |
| good        |      27 |
| sure        |      26 |
| bad         |      26 |
| procedural  |      26 |
| scared      |      25 |
| physical    |      25 |
| excessive   |      25 |
| severe      |      24 |
| illegal     |      24 |
